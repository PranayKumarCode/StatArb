{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea7a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import refinitiv.data as rd\n",
    "from refinitiv.data.content import historical_pricing as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alldata.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(type(data))\n",
    "print(data.keys())\n",
    "\n",
    "name_list = data['name_list']\n",
    "industry_list = data['industry_list']\n",
    "index_list = data['index_list']\n",
    "cusip_list = data['cusip_list']\n",
    "universe = data['universe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.open_session()\n",
    "\n",
    "ric = \"ABI.BR\"\n",
    "start_date = \"2019-09-01\"\n",
    "end_date = \"2025-08-01\"\n",
    "\n",
    "price_df = rd.get_history(\n",
    "    universe=ric,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    interval=\"daily\"\n",
    ")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'price': price_df['TRDPRC_1'],\n",
    "    'volume_shares': price_df['ACVOL_UNS'],\n",
    "    'bid': price_df['BID'],\n",
    "    'ask': price_df['ASK']\n",
    "})\n",
    "\n",
    "fundamental_response = rd.get_data(\n",
    "    universe=ric,\n",
    "    fields=[\n",
    "        \"TR.TotalReturn.Date\",\n",
    "        \"TR.TotalReturn\",           # Total Return Index\n",
    "        \"TR.PriceToBook\",           # Price to Book (Market-to-Book)\n",
    "        \"TR.CompanyMarketCap\"       # Market Cap\n",
    "    ],\n",
    "    parameters={\n",
    "        \"SDate\": start_date,\n",
    "        \"EDate\": end_date,\n",
    "        \"Frq\": \"D\",\n",
    "        \"Curn\": \"EUR\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nFundamental data response:\")\n",
    "print(fundamental_response.head(10))\n",
    "print(f\"\\nColumns: {fundamental_response.columns.tolist()}\")\n",
    "\n",
    "if fundamental_response is not None and isinstance(fundamental_response, pd.DataFrame):\n",
    "    fund_df = fundamental_response.copy()\n",
    "    \n",
    "    if 'Date' in fund_df.columns:\n",
    "        fund_df['Date'] = pd.to_datetime(fund_df['Date'])\n",
    "        fund_df.set_index('Date', inplace=True)\n",
    "        \n",
    "        if 'Instrument' in fund_df.columns:\n",
    "            fund_df.drop('Instrument', axis=1, inplace=True)\n",
    "        \n",
    "        print(f\"\\nFundamental data with Date index:\")\n",
    "        print(fund_df.head(10))\n",
    "        \n",
    "        df = df.join(fund_df, how='left')\n",
    "    else:\n",
    "        print(\"\\nWARNING: No Date column found in fundamental data!\")\n",
    "        print(\"Available columns:\", fund_df.columns.tolist())\n",
    "\n",
    "column_mapping = {\n",
    "    'Total Return': 'tri',\n",
    "    'Price To Book Value': 'mtbv',\n",
    "    'Company Market Cap': 'cap'\n",
    "}\n",
    "\n",
    "for old_name, new_name in column_mapping.items():\n",
    "    if old_name in df.columns:\n",
    "        df.rename(columns={old_name: new_name}, inplace=True)\n",
    "\n",
    "df['volume'] = df['volume_shares'] * df['price']\n",
    "df.drop('volume_shares', axis=1, inplace=True)\n",
    "\n",
    "if 'mtbv' in df.columns:\n",
    "    df['mtbv'] = df['mtbv'].ffill()\n",
    "if 'cap' in df.columns:\n",
    "    df['cap'] = df['cap'].ffill()\n",
    "\n",
    "desired_order = ['price', 'tri', 'volume', 'mtbv', 'cap', 'bid', 'ask']\n",
    "existing_cols = [col for col in desired_order if col in df.columns]\n",
    "df = df[existing_cols]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(df.head(15))\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nNull counts:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nSample with non-null data:\")\n",
    "print(df[df['tri'].notna()].head(10))\n",
    "\n",
    "df.to_csv(\"ABI_BR_Data.csv\", index=True)\n",
    "print(f\"\\nData saved to ABI_BR_Data.csv\")\n",
    "\n",
    "rd.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2bb338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe8b9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "rd.open_session()\n",
    "\n",
    "unique_rics = universe['RIC'].unique()\n",
    "print(f\"Total rows in universe: {len(universe)}\")\n",
    "print(f\"Unique RICs to process: {len(unique_rics)}\")\n",
    "\n",
    "start_date = \"2019-09-01\"\n",
    "end_date = \"2025-08-01\"\n",
    "\n",
    "all_data = []\n",
    "failed_rics = []\n",
    "\n",
    "total_rics = len(unique_rics)\n",
    "print(f\"\\nProcessing {total_rics} unique stocks...\")\n",
    "\n",
    "for idx, ric in enumerate(unique_rics, 1):\n",
    "    print(f\"[{idx}/{total_rics}] Processing {ric}...\", end=' ')\n",
    "    \n",
    "    try:\n",
    "        # --- Fetch historical PRICING data ---\n",
    "        price_df = rd.get_history(\n",
    "            universe=ric,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "            interval=\"daily\"\n",
    "        )\n",
    "        \n",
    "        # Extract only what we need\n",
    "        df = pd.DataFrame({\n",
    "            'RIC': ric,  # Add RIC column\n",
    "            'price': price_df['TRDPRC_1'],\n",
    "            'volume_shares': price_df['ACVOL_UNS'],\n",
    "            'bid': price_df['BID'],\n",
    "            'ask': price_df['ASK']\n",
    "        })\n",
    "        \n",
    "        # --- Fetch FUNDAMENTAL data WITH DATES ---\n",
    "        fundamental_response = rd.get_data(\n",
    "            universe=ric,\n",
    "            fields=[\n",
    "                \"TR.TotalReturn.Date\",\n",
    "                \"TR.TotalReturn\",\n",
    "                \"TR.PriceToBook\",\n",
    "                \"TR.CompanyMarketCap\"\n",
    "            ],\n",
    "            parameters={\n",
    "                \"SDate\": start_date,\n",
    "                \"EDate\": end_date,\n",
    "                \"Frq\": \"D\",\n",
    "                \"Curn\": \"EUR\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Process fundamental data\n",
    "        if fundamental_response is not None and isinstance(fundamental_response, pd.DataFrame):\n",
    "            fund_df = fundamental_response.copy()\n",
    "            \n",
    "            if 'Date' in fund_df.columns:\n",
    "                fund_df['Date'] = pd.to_datetime(fund_df['Date'])\n",
    "                fund_df.set_index('Date', inplace=True)\n",
    "                \n",
    "                if 'Instrument' in fund_df.columns:\n",
    "                    fund_df.drop('Instrument', axis=1, inplace=True)\n",
    "                \n",
    "                # Merge with price data\n",
    "                df = df.join(fund_df, how='left')\n",
    "        \n",
    "        # Rename columns\n",
    "        column_mapping = {\n",
    "            'Total Return': 'tri',\n",
    "            'Price To Book Value': 'mtbv',\n",
    "            'Company Market Cap': 'cap'\n",
    "        }\n",
    "        \n",
    "        for old_name, new_name in column_mapping.items():\n",
    "            if old_name in df.columns:\n",
    "                df.rename(columns={old_name: new_name}, inplace=True)\n",
    "        \n",
    "        # Compute volume in EUR\n",
    "        df['volume'] = df['volume_shares'] * df['price']\n",
    "        df.drop('volume_shares', axis=1, inplace=True)\n",
    "        \n",
    "        # Forward-fill mtbv and cap\n",
    "        if 'mtbv' in df.columns:\n",
    "            df['mtbv'] = df['mtbv'].ffill()\n",
    "        if 'cap' in df.columns:\n",
    "            df['cap'] = df['cap'].ffill()\n",
    "        \n",
    "        # Reset index to make Date a column\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'Date'}, inplace=True)\n",
    "        \n",
    "        # Reorder columns\n",
    "        desired_order = ['RIC', 'Date', 'price', 'tri', 'volume', 'mtbv', 'cap', 'bid', 'ask']\n",
    "        existing_cols = [col for col in desired_order if col in df.columns]\n",
    "        df = df[existing_cols]\n",
    "        \n",
    "        # Append to list\n",
    "        all_data.append(df)\n",
    "        \n",
    "        print(f\"✓ {len(df)} rows\")\n",
    "        \n",
    "        # Rate limiting - sleep briefly to avoid overwhelming the API\n",
    "        if idx % 10 == 0:\n",
    "            time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed: {e}\")\n",
    "        failed_rics.append(ric)\n",
    "        continue\n",
    "\n",
    "# --- 6. Combine all data ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Successfully processed: {len(all_data)} stocks\")\n",
    "print(f\"Failed: {len(failed_rics)} stocks\")\n",
    "\n",
    "if failed_rics:\n",
    "    print(f\"\\nFailed RICs:\")\n",
    "    for ric in failed_rics:\n",
    "        print(f\"  - {ric}\")\n",
    "\n",
    "# --- 7. Create combined DataFrame ---\n",
    "if all_data:\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    print(f\"\\nCombined dataset shape: {combined_df.shape}\")\n",
    "    print(f\"Date range: {combined_df['Date'].min()} to {combined_df['Date'].max()}\")\n",
    "    print(f\"Unique stocks: {combined_df['RIC'].nunique()}\")\n",
    "    \n",
    "    # Display sample\n",
    "    print(\"\\nSample data:\")\n",
    "    print(combined_df.head(10))\n",
    "    \n",
    "    # Save to CSV\n",
    "    combined_df.to_csv(\"all_stocks_data.csv\", index=False)\n",
    "    print(f\"\\n✓ Saved to all_stocks_data.csv\")\n",
    "    \n",
    "    # Show null counts\n",
    "    print(\"\\nNull counts by column:\")\n",
    "    print(combined_df.isnull().sum())\n",
    "else:\n",
    "    print(\"\\nNo data retrieved!\")\n",
    "\n",
    "# --- 8. Close session ---\n",
    "rd.close_session()\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b0c85a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RIC          0\n",
       "Date         0\n",
       "price     1430\n",
       "tri        396\n",
       "volume     474\n",
       "cap        881\n",
       "bid        513\n",
       "ask        590\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"all_stocks_data.csv\").isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18a4bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all_stocks_data.csv\")\n",
    "df[\"spread\"] = (df[\"ask\"]-df[\"bid\"]) / ((df[\"ask\"]+df[\"bid\"])/2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50b196a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Found 77 duplicate Date-RIC combinations\n",
      "Sample duplicates:\n",
      "Date        RIC        \n",
      "2019-11-04  ALMCP.PA          3\n",
      "2020-04-01  ALTT.PA^D20    1368\n",
      "2020-05-26  ARGX.BR           2\n",
      "2020-07-17  ADEA.OL^F24       2\n",
      "2020-11-06  INGC.PA^K20    1214\n",
      "dtype: int64\n",
      "\n",
      "Aggregating duplicates by taking the mean spread value...\n",
      "\n",
      "Pivot table shape: (1521, 410)\n",
      "Date range: 2019-09-02 to 2025-08-01\n",
      "Number of unique RICs (columns): 410\n",
      "Number of dates (rows): 1521\n",
      "\n",
      "Sample of pivot table (first 5 rows, first 5 columns):\n",
      "RIC           1COVG.DE      AALB.AS        ABB.ST        ABI.BR  ABIO.PA^J22\n",
      "Date                                                                        \n",
      "2019-09-02  23268570.0   5878419.31  2.886003e+08  5.804478e+07    382097.10\n",
      "2019-09-03  31323010.0   5884377.52  1.911779e+08  8.577293e+07    468123.30\n",
      "2019-09-04  29976230.0   6729846.64  2.636862e+08  8.990287e+07    263889.25\n",
      "2019-09-05  40698920.0  10429461.41  3.338759e+08  1.298802e+08    658993.75\n",
      "2019-09-06  31819200.0  10233738.39  2.809328e+08  1.272931e+08    528943.40\n",
      "\n",
      "✓ Saved to volume.csv\n",
      "\n",
      "Data completeness:\n",
      "  Total cells: 623,610\n",
      "  Null cells: 42,753\n",
      "  Non-null cells: 580,857\n",
      "  Coverage: 93.14%\n"
     ]
    }
   ],
   "source": [
    "duplicates = df.groupby(['Date', 'RIC']).size()\n",
    "duplicates = duplicates[duplicates > 1]\n",
    "\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"⚠ Found {len(duplicates)} duplicate Date-RIC combinations\")\n",
    "    print(f\"Sample duplicates:\")\n",
    "    print(duplicates.head())\n",
    "    print(\"\\nAggregating duplicates by taking the mean spread value...\")\n",
    "    \n",
    "    # Aggregate duplicates by taking the mean\n",
    "    df_agg = df.groupby(['Date', 'RIC'], as_index=False)['volume'].mean()\n",
    "else:\n",
    "    print(\"No duplicates found\")\n",
    "    df_agg = df[['Date', 'RIC', 'volume']].copy()\n",
    "\n",
    "# Create pivot table with Date as index (rows), RIC as columns, spread as values\n",
    "spread_pivot = df_agg.pivot(index='Date', columns='RIC', values='volume')\n",
    "\n",
    "print(f\"\\nPivot table shape: {spread_pivot.shape}\")\n",
    "print(f\"Date range: {spread_pivot.index.min()} to {spread_pivot.index.max()}\")\n",
    "print(f\"Number of unique RICs (columns): {len(spread_pivot.columns)}\")\n",
    "print(f\"Number of dates (rows): {len(spread_pivot.index)}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample of pivot table (first 5 rows, first 5 columns):\")\n",
    "print(spread_pivot.iloc[:5, :5])\n",
    "\n",
    "# Save to CSV\n",
    "spread_pivot.to_csv('volume.csv')\n",
    "print(\"\\n✓ Saved to volume.csv\")\n",
    "\n",
    "# Show null count summary\n",
    "total_cells = spread_pivot.shape[0] * spread_pivot.shape[1]\n",
    "null_cells = spread_pivot.isna().sum().sum()\n",
    "print(f\"\\nData completeness:\")\n",
    "print(f\"  Total cells: {total_cells:,}\")\n",
    "print(f\"  Null cells: {null_cells:,}\")\n",
    "print(f\"  Non-null cells: {total_cells - null_cells:,}\")\n",
    "print(f\"  Coverage: {((total_cells - null_cells) / total_cells * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616eaa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
