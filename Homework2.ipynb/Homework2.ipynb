{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import refinitiv.data as rd\n",
    "from refinitiv.data.content import historical_pricing as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alldata.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(type(data))\n",
    "print(data.keys())\n",
    "\n",
    "name_list = data['name_list']\n",
    "industry_list = data['industry_list']\n",
    "index_list = data['index_list']\n",
    "cusip_list = data['cusip_list']\n",
    "universe = data['universe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.open_session()\n",
    "\n",
    "ric = \"ABI.BR\"\n",
    "start_date = \"2019-09-01\"\n",
    "end_date = \"2025-08-01\"\n",
    "\n",
    "price_df = rd.get_history(\n",
    "    universe=ric,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    interval=\"daily\"\n",
    ")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'price': price_df['TRDPRC_1'],\n",
    "    'volume_shares': price_df['ACVOL_UNS'],\n",
    "    'bid': price_df['BID'],\n",
    "    'ask': price_df['ASK']\n",
    "})\n",
    "\n",
    "fundamental_response = rd.get_data(\n",
    "    universe=ric,\n",
    "    fields=[\n",
    "        \"TR.TotalReturn.Date\",\n",
    "        \"TR.TotalReturn\",           # Total Return Index\n",
    "        \"TR.PriceToBook\",           # Price to Book (Market-to-Book)\n",
    "        \"TR.CompanyMarketCap\"       # Market Cap\n",
    "    ],\n",
    "    parameters={\n",
    "        \"SDate\": start_date,\n",
    "        \"EDate\": end_date,\n",
    "        \"Frq\": \"D\",\n",
    "        \"Curn\": \"EUR\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nFundamental data response:\")\n",
    "print(fundamental_response.head(10))\n",
    "print(f\"\\nColumns: {fundamental_response.columns.tolist()}\")\n",
    "\n",
    "if fundamental_response is not None and isinstance(fundamental_response, pd.DataFrame):\n",
    "    fund_df = fundamental_response.copy()\n",
    "    \n",
    "    if 'Date' in fund_df.columns:\n",
    "        fund_df['Date'] = pd.to_datetime(fund_df['Date'])\n",
    "        fund_df.set_index('Date', inplace=True)\n",
    "        \n",
    "        if 'Instrument' in fund_df.columns:\n",
    "            fund_df.drop('Instrument', axis=1, inplace=True)\n",
    "        \n",
    "        print(f\"\\nFundamental data with Date index:\")\n",
    "        print(fund_df.head(10))\n",
    "        \n",
    "        df = df.join(fund_df, how='left')\n",
    "    else:\n",
    "        print(\"\\nWARNING: No Date column found in fundamental data!\")\n",
    "        print(\"Available columns:\", fund_df.columns.tolist())\n",
    "\n",
    "column_mapping = {\n",
    "    'Total Return': 'tri',\n",
    "    'Price To Book Value': 'mtbv',\n",
    "    'Company Market Cap': 'cap'\n",
    "}\n",
    "\n",
    "for old_name, new_name in column_mapping.items():\n",
    "    if old_name in df.columns:\n",
    "        df.rename(columns={old_name: new_name}, inplace=True)\n",
    "\n",
    "df['volume'] = df['volume_shares'] * df['price']\n",
    "df.drop('volume_shares', axis=1, inplace=True)\n",
    "\n",
    "if 'mtbv' in df.columns:\n",
    "    df['mtbv'] = df['mtbv'].ffill()\n",
    "if 'cap' in df.columns:\n",
    "    df['cap'] = df['cap'].ffill()\n",
    "\n",
    "desired_order = ['price', 'tri', 'volume', 'mtbv', 'cap', 'bid', 'ask']\n",
    "existing_cols = [col for col in desired_order if col in df.columns]\n",
    "df = df[existing_cols]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(df.head(15))\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nNull counts:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nSample with non-null data:\")\n",
    "print(df[df['tri'].notna()].head(10))\n",
    "\n",
    "df.to_csv(\"ABI_BR_Data.csv\", index=True)\n",
    "print(f\"\\nData saved to ABI_BR_Data.csv\")\n",
    "\n",
    "rd.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2bb338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe8b9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "rd.open_session()\n",
    "\n",
    "unique_rics = universe['RIC'].unique()\n",
    "print(f\"Total rows in universe: {len(universe)}\")\n",
    "print(f\"Unique RICs to process: {len(unique_rics)}\")\n",
    "\n",
    "start_date = \"2019-09-01\"\n",
    "end_date = \"2025-08-01\"\n",
    "\n",
    "all_data = []\n",
    "failed_rics = []\n",
    "\n",
    "total_rics = len(unique_rics)\n",
    "print(f\"\\nProcessing {total_rics} unique stocks...\")\n",
    "\n",
    "for idx, ric in enumerate(unique_rics, 1):\n",
    "    print(f\"[{idx}/{total_rics}] Processing {ric}...\", end=' ')\n",
    "    \n",
    "    try:\n",
    "        # --- Fetch historical PRICING data ---\n",
    "        price_df = rd.get_history(\n",
    "            universe=ric,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "            interval=\"daily\"\n",
    "        )\n",
    "        \n",
    "        # Extract only what we need\n",
    "        df = pd.DataFrame({\n",
    "            'RIC': ric,  # Add RIC column\n",
    "            'price': price_df['TRDPRC_1'],\n",
    "            'volume_shares': price_df['ACVOL_UNS'],\n",
    "            'bid': price_df['BID'],\n",
    "            'ask': price_df['ASK']\n",
    "        })\n",
    "        \n",
    "        # --- Fetch FUNDAMENTAL data WITH DATES ---\n",
    "        fundamental_response = rd.get_data(\n",
    "            universe=ric,\n",
    "            fields=[\n",
    "                \"TR.TotalReturn.Date\",\n",
    "                \"TR.TotalReturn\",\n",
    "                \"TR.PriceToBook\",\n",
    "                \"TR.CompanyMarketCap\"\n",
    "            ],\n",
    "            parameters={\n",
    "                \"SDate\": start_date,\n",
    "                \"EDate\": end_date,\n",
    "                \"Frq\": \"D\",\n",
    "                \"Curn\": \"EUR\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Process fundamental data\n",
    "        if fundamental_response is not None and isinstance(fundamental_response, pd.DataFrame):\n",
    "            fund_df = fundamental_response.copy()\n",
    "            \n",
    "            if 'Date' in fund_df.columns:\n",
    "                fund_df['Date'] = pd.to_datetime(fund_df['Date'])\n",
    "                fund_df.set_index('Date', inplace=True)\n",
    "                \n",
    "                if 'Instrument' in fund_df.columns:\n",
    "                    fund_df.drop('Instrument', axis=1, inplace=True)\n",
    "                \n",
    "                # Merge with price data\n",
    "                df = df.join(fund_df, how='left')\n",
    "        \n",
    "        # Rename columns\n",
    "        column_mapping = {\n",
    "            'Total Return': 'tri',\n",
    "            'Price To Book Value': 'mtbv',\n",
    "            'Company Market Cap': 'cap'\n",
    "        }\n",
    "        \n",
    "        for old_name, new_name in column_mapping.items():\n",
    "            if old_name in df.columns:\n",
    "                df.rename(columns={old_name: new_name}, inplace=True)\n",
    "        \n",
    "        # Compute volume in EUR\n",
    "        df['volume'] = df['volume_shares'] * df['price']\n",
    "        df.drop('volume_shares', axis=1, inplace=True)\n",
    "        \n",
    "        # Forward-fill mtbv and cap\n",
    "        if 'mtbv' in df.columns:\n",
    "            df['mtbv'] = df['mtbv'].ffill()\n",
    "        if 'cap' in df.columns:\n",
    "            df['cap'] = df['cap'].ffill()\n",
    "        \n",
    "        # Reset index to make Date a column\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'Date'}, inplace=True)\n",
    "        \n",
    "        # Reorder columns\n",
    "        desired_order = ['RIC', 'Date', 'price', 'tri', 'volume', 'mtbv', 'cap', 'bid', 'ask']\n",
    "        existing_cols = [col for col in desired_order if col in df.columns]\n",
    "        df = df[existing_cols]\n",
    "        \n",
    "        # Append to list\n",
    "        all_data.append(df)\n",
    "        \n",
    "        print(f\"✓ {len(df)} rows\")\n",
    "        \n",
    "        # Rate limiting - sleep briefly to avoid overwhelming the API\n",
    "        if idx % 10 == 0:\n",
    "            time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed: {e}\")\n",
    "        failed_rics.append(ric)\n",
    "        continue\n",
    "\n",
    "# --- 6. Combine all data ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Successfully processed: {len(all_data)} stocks\")\n",
    "print(f\"Failed: {len(failed_rics)} stocks\")\n",
    "\n",
    "if failed_rics:\n",
    "    print(f\"\\nFailed RICs:\")\n",
    "    for ric in failed_rics:\n",
    "        print(f\"  - {ric}\")\n",
    "\n",
    "# --- 7. Create combined DataFrame ---\n",
    "if all_data:\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    print(f\"\\nCombined dataset shape: {combined_df.shape}\")\n",
    "    print(f\"Date range: {combined_df['Date'].min()} to {combined_df['Date'].max()}\")\n",
    "    print(f\"Unique stocks: {combined_df['RIC'].nunique()}\")\n",
    "    \n",
    "    # Display sample\n",
    "    print(\"\\nSample data:\")\n",
    "    print(combined_df.head(10))\n",
    "    \n",
    "    # Save to CSV\n",
    "    combined_df.to_csv(\"all_stocks_data.csv\", index=False)\n",
    "    print(f\"\\n✓ Saved to all_stocks_data.csv\")\n",
    "    \n",
    "    # Show null counts\n",
    "    print(\"\\nNull counts by column:\")\n",
    "    print(combined_df.isnull().sum())\n",
    "else:\n",
    "    print(\"\\nNo data retrieved!\")\n",
    "\n",
    "# --- 8. Close session ---\n",
    "rd.close_session()\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b0c85a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RIC            0\n",
       "Date           0\n",
       "price       1410\n",
       "tri          376\n",
       "volume    332768\n",
       "cap         3050\n",
       "bid          499\n",
       "ask          570\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"all_stocks_data.csv\").isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f7bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
