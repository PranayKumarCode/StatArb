{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import refinitiv.data as rd\n",
    "from refinitiv.data.content import historical_pricing as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alldata.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(type(data))\n",
    "print(data.keys())\n",
    "\n",
    "name_list = data['name_list']\n",
    "industry_list = data['industry_list']\n",
    "index_list = data['index_list']\n",
    "cusip_list = data['cusip_list']\n",
    "universe = data['universe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.open_session()\n",
    "\n",
    "ric = \"ABI.BR\"\n",
    "start_date = \"2019-09-01\"\n",
    "end_date = \"2025-08-01\"\n",
    "\n",
    "price_df = rd.get_history(\n",
    "    universe=ric,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    interval=\"daily\"\n",
    ")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'price': price_df['TRDPRC_1'],\n",
    "    'volume_shares': price_df['ACVOL_UNS'],\n",
    "    'bid': price_df['BID'],\n",
    "    'ask': price_df['ASK']\n",
    "})\n",
    "\n",
    "fundamental_response = rd.get_data(\n",
    "    universe=ric,\n",
    "    fields=[\n",
    "        \"TR.TotalReturn.Date\",\n",
    "        \"TR.TotalReturn\",           # Total Return Index\n",
    "        \"TR.PriceToBook\",           # Price to Book (Market-to-Book)\n",
    "        \"TR.CompanyMarketCap\"       # Market Cap\n",
    "    ],\n",
    "    parameters={\n",
    "        \"SDate\": start_date,\n",
    "        \"EDate\": end_date,\n",
    "        \"Frq\": \"D\",\n",
    "        \"Curn\": \"EUR\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nFundamental data response:\")\n",
    "print(fundamental_response.head(10))\n",
    "print(f\"\\nColumns: {fundamental_response.columns.tolist()}\")\n",
    "\n",
    "if fundamental_response is not None and isinstance(fundamental_response, pd.DataFrame):\n",
    "    fund_df = fundamental_response.copy()\n",
    "    \n",
    "    if 'Date' in fund_df.columns:\n",
    "        fund_df['Date'] = pd.to_datetime(fund_df['Date'])\n",
    "        fund_df.set_index('Date', inplace=True)\n",
    "        \n",
    "        if 'Instrument' in fund_df.columns:\n",
    "            fund_df.drop('Instrument', axis=1, inplace=True)\n",
    "        \n",
    "        print(f\"\\nFundamental data with Date index:\")\n",
    "        print(fund_df.head(10))\n",
    "        \n",
    "        df = df.join(fund_df, how='left')\n",
    "    else:\n",
    "        print(\"\\nWARNING: No Date column found in fundamental data!\")\n",
    "        print(\"Available columns:\", fund_df.columns.tolist())\n",
    "\n",
    "column_mapping = {\n",
    "    'Total Return': 'tri',\n",
    "    'Price To Book Value': 'mtbv',\n",
    "    'Company Market Cap': 'cap'\n",
    "}\n",
    "\n",
    "for old_name, new_name in column_mapping.items():\n",
    "    if old_name in df.columns:\n",
    "        df.rename(columns={old_name: new_name}, inplace=True)\n",
    "\n",
    "df['volume'] = df['volume_shares'] * df['price']\n",
    "df.drop('volume_shares', axis=1, inplace=True)\n",
    "\n",
    "if 'mtbv' in df.columns:\n",
    "    df['mtbv'] = df['mtbv'].ffill()\n",
    "if 'cap' in df.columns:\n",
    "    df['cap'] = df['cap'].ffill()\n",
    "\n",
    "desired_order = ['price', 'tri', 'volume', 'mtbv', 'cap', 'bid', 'ask']\n",
    "existing_cols = [col for col in desired_order if col in df.columns]\n",
    "df = df[existing_cols]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(df.head(15))\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nNull counts:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nSample with non-null data:\")\n",
    "print(df[df['tri'].notna()].head(10))\n",
    "\n",
    "df.to_csv(\"ABI_BR_Data.csv\", index=True)\n",
    "print(f\"\\nData saved to ABI_BR_Data.csv\")\n",
    "\n",
    "rd.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2bb338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe8b9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "rd.open_session()\n",
    "\n",
    "unique_rics = universe['RIC'].unique()\n",
    "print(f\"Total rows in universe: {len(universe)}\")\n",
    "print(f\"Unique RICs to process: {len(unique_rics)}\")\n",
    "\n",
    "start_date = \"2019-09-01\"\n",
    "end_date = \"2025-08-01\"\n",
    "\n",
    "all_data = []\n",
    "failed_rics = []\n",
    "\n",
    "total_rics = len(unique_rics)\n",
    "print(f\"\\nProcessing {total_rics} unique stocks...\")\n",
    "\n",
    "for idx, ric in enumerate(unique_rics, 1):\n",
    "    print(f\"[{idx}/{total_rics}] Processing {ric}...\", end=' ')\n",
    "    \n",
    "    try:\n",
    "        # --- Fetch historical PRICING data ---\n",
    "        price_df = rd.get_history(\n",
    "            universe=ric,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "            interval=\"daily\"\n",
    "        )\n",
    "        \n",
    "        # Extract only what we need\n",
    "        df = pd.DataFrame({\n",
    "            'RIC': ric,  # Add RIC column\n",
    "            'price': price_df['TRDPRC_1'],\n",
    "            'volume_shares': price_df['ACVOL_UNS'],\n",
    "            'bid': price_df['BID'],\n",
    "            'ask': price_df['ASK']\n",
    "        })\n",
    "        \n",
    "        # --- Fetch FUNDAMENTAL data WITH DATES ---\n",
    "        fundamental_response = rd.get_data(\n",
    "            universe=ric,\n",
    "            fields=[\n",
    "                \"TR.TotalReturn.Date\",\n",
    "                \"TR.TotalReturn\",\n",
    "                \"TR.PriceToBook\",\n",
    "                \"TR.CompanyMarketCap\"\n",
    "            ],\n",
    "            parameters={\n",
    "                \"SDate\": start_date,\n",
    "                \"EDate\": end_date,\n",
    "                \"Frq\": \"D\",\n",
    "                \"Curn\": \"EUR\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Process fundamental data\n",
    "        if fundamental_response is not None and isinstance(fundamental_response, pd.DataFrame):\n",
    "            fund_df = fundamental_response.copy()\n",
    "            \n",
    "            if 'Date' in fund_df.columns:\n",
    "                fund_df['Date'] = pd.to_datetime(fund_df['Date'])\n",
    "                fund_df.set_index('Date', inplace=True)\n",
    "                \n",
    "                if 'Instrument' in fund_df.columns:\n",
    "                    fund_df.drop('Instrument', axis=1, inplace=True)\n",
    "                \n",
    "                # Merge with price data\n",
    "                df = df.join(fund_df, how='left')\n",
    "        \n",
    "        # Rename columns\n",
    "        column_mapping = {\n",
    "            'Total Return': 'tri',\n",
    "            'Price To Book Value': 'mtbv',\n",
    "            'Company Market Cap': 'cap'\n",
    "        }\n",
    "        \n",
    "        for old_name, new_name in column_mapping.items():\n",
    "            if old_name in df.columns:\n",
    "                df.rename(columns={old_name: new_name}, inplace=True)\n",
    "        \n",
    "        # Compute volume in EUR\n",
    "        df['volume'] = df['volume_shares'] * df['price']\n",
    "        df.drop('volume_shares', axis=1, inplace=True)\n",
    "        \n",
    "        # Forward-fill mtbv and cap\n",
    "        if 'mtbv' in df.columns:\n",
    "            df['mtbv'] = df['mtbv'].ffill()\n",
    "        if 'cap' in df.columns:\n",
    "            df['cap'] = df['cap'].ffill()\n",
    "        \n",
    "        # Reset index to make Date a column\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'Date'}, inplace=True)\n",
    "        \n",
    "        # Reorder columns\n",
    "        desired_order = ['RIC', 'Date', 'price', 'tri', 'volume', 'mtbv', 'cap', 'bid', 'ask']\n",
    "        existing_cols = [col for col in desired_order if col in df.columns]\n",
    "        df = df[existing_cols]\n",
    "        \n",
    "        # Append to list\n",
    "        all_data.append(df)\n",
    "        \n",
    "        print(f\"✓ {len(df)} rows\")\n",
    "        \n",
    "        # Rate limiting - sleep briefly to avoid overwhelming the API\n",
    "        if idx % 10 == 0:\n",
    "            time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed: {e}\")\n",
    "        failed_rics.append(ric)\n",
    "        continue\n",
    "\n",
    "# --- 6. Combine all data ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Successfully processed: {len(all_data)} stocks\")\n",
    "print(f\"Failed: {len(failed_rics)} stocks\")\n",
    "\n",
    "if failed_rics:\n",
    "    print(f\"\\nFailed RICs:\")\n",
    "    for ric in failed_rics:\n",
    "        print(f\"  - {ric}\")\n",
    "\n",
    "# --- 7. Create combined DataFrame ---\n",
    "if all_data:\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    print(f\"\\nCombined dataset shape: {combined_df.shape}\")\n",
    "    print(f\"Date range: {combined_df['Date'].min()} to {combined_df['Date'].max()}\")\n",
    "    print(f\"Unique stocks: {combined_df['RIC'].nunique()}\")\n",
    "    \n",
    "    # Display sample\n",
    "    print(\"\\nSample data:\")\n",
    "    print(combined_df.head(10))\n",
    "    \n",
    "    # Save to CSV\n",
    "    combined_df.to_csv(\"all_stocks_data.csv\", index=False)\n",
    "    print(f\"\\n✓ Saved to all_stocks_data.csv\")\n",
    "    \n",
    "    # Show null counts\n",
    "    print(\"\\nNull counts by column:\")\n",
    "    print(combined_df.isnull().sum())\n",
    "else:\n",
    "    print(\"\\nNo data retrieved!\")\n",
    "\n",
    "# --- 8. Close session ---\n",
    "rd.close_session()\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390b70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4313fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = set(universe['RIC'].unique()) - set(pd.read_csv(\"all_stocks_data.csv\")['RIC'].unique())\n",
    "print(f\"Missing: {len(missing)} RICs\")\n",
    "print(sorted(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21cffb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7fc5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all_stocks_data.csv\")\n",
    "\n",
    "myday = df[['Date']].drop_duplicates().sort_values('Date')\n",
    "myday.to_csv(\"myday.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b35bb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv(\"all_stocks_data.csv\")\n",
    "\n",
    "print(\"Analyzing existing data for incomplete RICs...\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Columns in CSV: {combined_df.columns.tolist()}\")\n",
    "print(f\"Shape: {combined_df.shape}\")\n",
    "\n",
    "# --- Find RICs with ANY missing data ---\n",
    "# Only check columns that actually exist\n",
    "columns_to_check = ['price', 'tri', 'volume', 'cap', 'bid', 'ask']\n",
    "existing_columns = [col for col in columns_to_check if col in combined_df.columns]\n",
    "\n",
    "print(f\"\\nChecking these columns for missing data: {existing_columns}\")\n",
    "\n",
    "agg_dict = {col: lambda x: x.isnull().sum() for col in existing_columns}\n",
    "\n",
    "rics_with_missing = combined_df.groupby('RIC').agg(agg_dict).reset_index()\n",
    "\n",
    "# Calculate total missing per RIC\n",
    "rics_with_missing['total_missing'] = rics_with_missing[existing_columns].sum(axis=1)\n",
    "\n",
    "# Filter to only RICs with ANY missing data\n",
    "incomplete_rics = rics_with_missing[rics_with_missing['total_missing'] > 0]['RIC'].tolist()\n",
    "\n",
    "print(f\"\\nRICs with complete data: {len(rics_with_missing) - len(incomplete_rics)}\")\n",
    "print(f\"RICs with missing data: {len(incomplete_rics)}\")\n",
    "\n",
    "if len(incomplete_rics) == 0:\n",
    "    print(\"\\nNo incomplete RICs found! All data is complete.\")\n",
    "else:\n",
    "    print(f\"\\nIncomplete RICs: {incomplete_rics[:20]}\")  # Show first 20\n",
    "    if len(incomplete_rics) > 20:\n",
    "        print(f\"... and {len(incomplete_rics) - 20} more\")\n",
    "    \n",
    "    # Show summary of what's missing\n",
    "    print(\"\\nMissing data breakdown for incomplete RICs:\")\n",
    "    print(rics_with_missing[rics_with_missing['total_missing'] > 0].sort_values('total_missing', ascending=False).head(20))\n",
    "\n",
    "# --- Retry all incomplete RICs ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"RETRYING {len(incomplete_rics)} INCOMPLETE RICs\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rd.open_session()\n",
    "\n",
    "retry_data = []\n",
    "retry_failed = {}\n",
    "\n",
    "start_date = \"2019-09-01\"\n",
    "end_date = \"2025-08-01\"\n",
    "\n",
    "for idx, ric in enumerate(incomplete_rics, 1):\n",
    "    print(f\"[{idx}/{len(incomplete_rics)}] Processing {ric}...\", end=' ')\n",
    "    \n",
    "    try:\n",
    "        # --- Fetch historical PRICING data ---\n",
    "        price_df = rd.get_history(\n",
    "            universe=ric,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "            interval=\"daily\"\n",
    "        )\n",
    "        \n",
    "        # Extract only what we need\n",
    "        df = pd.DataFrame({\n",
    "            'RIC': ric,\n",
    "            'price': price_df['TRDPRC_1'] if 'TRDPRC_1' in price_df.columns else None,\n",
    "            'volume_shares': price_df['ACVOL_UNS'] if 'ACVOL_UNS' in price_df.columns else None,\n",
    "            'bid': price_df['BID'] if 'BID' in price_df.columns else None,\n",
    "            'ask': price_df['ASK'] if 'ASK' in price_df.columns else None\n",
    "        })\n",
    "        \n",
    "        # --- Fetch FUNDAMENTAL data WITH DATES ---\n",
    "        try:\n",
    "            fundamental_response = rd.get_data(\n",
    "                universe=ric,\n",
    "                fields=[\n",
    "                    \"TR.TotalReturn.Date\",\n",
    "                    \"TR.TotalReturn\",\n",
    "                    \"TR.PriceToBook\",\n",
    "                    \"TR.CompanyMarketCap\"\n",
    "                ],\n",
    "                parameters={\n",
    "                    \"SDate\": start_date,\n",
    "                    \"EDate\": end_date,\n",
    "                    \"Frq\": \"D\",\n",
    "                    \"Curn\": \"EUR\"\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Process fundamental data\n",
    "            if fundamental_response is not None and isinstance(fundamental_response, pd.DataFrame):\n",
    "                fund_df = fundamental_response.copy()\n",
    "                \n",
    "                if 'Date' in fund_df.columns:\n",
    "                    fund_df['Date'] = pd.to_datetime(fund_df['Date'])\n",
    "                    fund_df.set_index('Date', inplace=True)\n",
    "                    \n",
    "                    if 'Instrument' in fund_df.columns:\n",
    "                        fund_df.drop('Instrument', axis=1, inplace=True)\n",
    "                    \n",
    "                    # Merge with price data\n",
    "                    df = df.join(fund_df, how='left')\n",
    "        \n",
    "        except Exception as fund_error:\n",
    "            pass  # Continue even if fundamentals fail\n",
    "        \n",
    "        # Rename columns\n",
    "        column_mapping = {\n",
    "            'Total Return': 'tri',\n",
    "            'Price To Book Value': 'mtbv',\n",
    "            'Company Market Cap': 'cap'\n",
    "        }\n",
    "        \n",
    "        for old_name, new_name in column_mapping.items():\n",
    "            if old_name in df.columns:\n",
    "                df.rename(columns={old_name: new_name}, inplace=True)\n",
    "        \n",
    "        # Compute volume in EUR\n",
    "        if 'volume_shares' in df.columns and 'price' in df.columns:\n",
    "            df['volume'] = df['volume_shares'] * df['price']\n",
    "            df.drop('volume_shares', axis=1, inplace=True)\n",
    "        \n",
    "        # Forward-fill mtbv and cap\n",
    "        if 'mtbv' in df.columns:\n",
    "            df['mtbv'] = df['mtbv'].ffill()\n",
    "        if 'cap' in df.columns:\n",
    "            df['cap'] = df['cap'].ffill()\n",
    "        \n",
    "        # Reset index to make Date a column\n",
    "        df.reset_index(inplace=True)\n",
    "        if 'index' in df.columns:\n",
    "            df.rename(columns={'index': 'Date'}, inplace=True)\n",
    "        \n",
    "        # Reorder columns - only include columns that exist\n",
    "        desired_order = ['RIC', 'Date', 'price', 'tri', 'volume', 'mtbv', 'cap', 'bid', 'ask']\n",
    "        existing_cols = [col for col in desired_order if col in df.columns]\n",
    "        df = df[existing_cols]\n",
    "        \n",
    "        # Append to list\n",
    "        retry_data.append(df)\n",
    "        \n",
    "        print(f\"✓ {len(df)} rows\")\n",
    "        \n",
    "        # Rate limiting\n",
    "        if idx % 10 == 0:\n",
    "            time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed: {e}\")\n",
    "        retry_failed[ric] = str(e)\n",
    "        continue\n",
    "\n",
    "rd.close_session()\n",
    "\n",
    "# --- Save retry results ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RETRY COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if retry_data:\n",
    "    attempt2_df = pd.concat(retry_data, ignore_index=True)\n",
    "    \n",
    "    print(f\"Successfully re-retrieved: {len(retry_data)} RICs\")\n",
    "    print(f\"Failed on retry: {len(retry_failed)} RICs\")\n",
    "    print(f\"Total rows in attempt2: {len(attempt2_df)}\")\n",
    "    print(f\"Date range: {attempt2_df['Date'].min()} to {attempt2_df['Date'].max()}\")\n",
    "    \n",
    "    # Check if data is still incomplete\n",
    "    print(\"\\nMissing data in attempt2:\")\n",
    "    print(attempt2_df.isnull().sum())\n",
    "    \n",
    "    # Save to CSV\n",
    "    attempt2_df.to_csv(\"attempt2.csv\", index=False)\n",
    "    print(f\"\\n✓ Saved to attempt2.csv\")\n",
    "    \n",
    "    # Show which RICs still have issues\n",
    "    rics_still_incomplete = attempt2_df.groupby('RIC').apply(\n",
    "        lambda x: x.isnull().sum().sum()\n",
    "    )\n",
    "    rics_still_incomplete = rics_still_incomplete[rics_still_incomplete > 0]\n",
    "    \n",
    "    if len(rics_still_incomplete) > 0:\n",
    "        print(f\"\\nWarning: {len(rics_still_incomplete)} RICs still have missing data after retry:\")\n",
    "        print(rics_still_incomplete.sort_values(ascending=False).head(20))\n",
    "else:\n",
    "    print(\"\\nNo data retrieved on retry!\")\n",
    "\n",
    "if retry_failed:\n",
    "    print(f\"\\nFailed RICs:\")\n",
    "    for ric, error in list(retry_failed.items())[:10]:\n",
    "        print(f\"  {ric}: {error[:80]}\")\n",
    "    \n",
    "    # Save failed list\n",
    "    pd.DataFrame([\n",
    "        {'RIC': ric, 'Error': error} \n",
    "        for ric, error in retry_failed.items()\n",
    "    ]).to_csv(\"retry_failed_rics.csv\", index=False)\n",
    "    print(f\"\\n✓ Saved failed RICs to retry_failed_rics.csv\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84720a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"attempt2.csv\").isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88335e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da5346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv(\"all_stocks_data.csv\")\n",
    "universe_unique = universe['RIC'].unique()\n",
    "\n",
    "missing_rics = set(universe_unique) - set(combined_df['RIC'].unique())\n",
    "missing_rics = sorted(missing_rics)\n",
    "\n",
    "print(f\"Found {len(missing_rics)} missing RICs\")\n",
    "print(f\"Missing RICs: {missing_rics[:10]}...\")  # Show first 10\n",
    "\n",
    "\n",
    "pd.DataFrame({'RIC': missing_rics}).to_csv(\"completely_missing_rics.csv\", index=False)\n",
    "\n",
    "\n",
    "# --- Retry missing RICs with detailed error messages ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RETRYING FAILED RICs\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rd.open_session()\n",
    "\n",
    "retry_data = []\n",
    "still_failed = {}\n",
    "\n",
    "for idx, ric in enumerate(missing_rics, 1):\n",
    "    print(f\"\\n[{idx}/{len(missing_rics)}] Retrying {ric}...\")\n",
    "    \n",
    "    try:\n",
    "        # Try with a shorter date range first to see if data exists\n",
    "        test_df = rd.get_history(\n",
    "            universe=ric,\n",
    "            start=\"2024-01-01\",\n",
    "            end=\"2024-12-31\",\n",
    "            interval=\"daily\"\n",
    "        )\n",
    "        \n",
    "        print(f\"  Test fetch: {len(test_df)} rows returned\")\n",
    "        print(f\"  Available fields: {test_df.columns.tolist()}\")\n",
    "        \n",
    "        # If test works, fetch full range\n",
    "        price_df = rd.get_history(\n",
    "            universe=ric,\n",
    "            start=\"2019-09-01\",\n",
    "            end=\"2025-08-01\",\n",
    "            interval=\"daily\"\n",
    "        )\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'RIC': ric,\n",
    "            'price': price_df['TRDPRC_1'] if 'TRDPRC_1' in price_df.columns else None,\n",
    "            'volume_shares': price_df['ACVOL_UNS'] if 'ACVOL_UNS' in price_df.columns else None,\n",
    "            'bid': price_df['BID'] if 'BID' in price_df.columns else None,\n",
    "            'ask': price_df['ASK'] if 'ASK' in price_df.columns else None\n",
    "        })\n",
    "        \n",
    "        # Try fundamentals\n",
    "        try:\n",
    "            fundamental_response = rd.get_data(\n",
    "                universe=ric,\n",
    "                fields=[\n",
    "                    \"TR.TotalReturn.Date\",\n",
    "                    \"TR.TotalReturn\",\n",
    "                    \"TR.PriceToBook\",\n",
    "                    \"TR.CompanyMarketCap\"\n",
    "                ],\n",
    "                parameters={\n",
    "                    \"SDate\": \"2019-09-01\",\n",
    "                    \"EDate\": \"2025-08-01\",\n",
    "                    \"Frq\": \"D\",\n",
    "                    \"Curn\": \"EUR\"\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            if fundamental_response is not None and isinstance(fundamental_response, pd.DataFrame):\n",
    "                fund_df = fundamental_response.copy()\n",
    "                \n",
    "                if 'Date' in fund_df.columns:\n",
    "                    fund_df['Date'] = pd.to_datetime(fund_df['Date'])\n",
    "                    fund_df.set_index('Date', inplace=True)\n",
    "                    \n",
    "                    if 'Instrument' in fund_df.columns:\n",
    "                        fund_df.drop('Instrument', axis=1, inplace=True)\n",
    "                    \n",
    "                    df = df.join(fund_df, how='left')\n",
    "        except Exception as fund_error:\n",
    "            print(f\"  Warning: Fundamentals failed: {fund_error}\")\n",
    "        \n",
    "        # Rename columns\n",
    "        column_mapping = {\n",
    "            'Total Return': 'tri',\n",
    "            'Price To Book Value': 'mtbv',\n",
    "            'Company Market Cap': 'cap'\n",
    "        }\n",
    "        \n",
    "        for old_name, new_name in column_mapping.items():\n",
    "            if old_name in df.columns:\n",
    "                df.rename(columns={old_name: new_name}, inplace=True)\n",
    "        \n",
    "        # Compute volume in EUR\n",
    "        if 'volume_shares' in df.columns and 'price' in df.columns:\n",
    "            df['volume'] = df['volume_shares'] * df['price']\n",
    "            df.drop('volume_shares', axis=1, inplace=True)\n",
    "        \n",
    "        # Forward-fill\n",
    "        if 'mtbv' in df.columns:\n",
    "            df['mtbv'] = df['mtbv'].ffill()\n",
    "        if 'cap' in df.columns:\n",
    "            df['cap'] = df['cap'].ffill()\n",
    "        \n",
    "        # Reset index\n",
    "        df.reset_index(inplace=True)\n",
    "        if 'index' in df.columns:\n",
    "            df.rename(columns={'index': 'Date'}, inplace=True)\n",
    "        \n",
    "        # Reorder columns\n",
    "        desired_order = ['RIC', 'Date', 'price', 'tri', 'volume', 'mtbv', 'cap', 'bid', 'ask']\n",
    "        existing_cols = [col for col in desired_order if col in df.columns]\n",
    "        df = df[existing_cols]\n",
    "        \n",
    "        retry_data.append(df)\n",
    "        print(f\"  ✓ Success: {len(df)} rows\")\n",
    "        \n",
    "        if idx % 5 == 0:\n",
    "            time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"  ✗ Failed: {error_msg}\")\n",
    "        still_failed[ric] = error_msg\n",
    "        continue\n",
    "\n",
    "rd.close_session()\n",
    "\n",
    "if retry_data:\n",
    "    all_retry_df = pd.concat(retry_data, ignore_index=True)\n",
    "    all_retry_df.to_csv(\"missing.csv\", index=False)\n",
    "    print(f\"Saved {len(all_retry_df)} rows to missing.csv\")\n",
    "else:\n",
    "    print(\"No data was successfully retrieved for missing RICs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4c005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba94288",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv(\"all_stocks_data.csv\")\n",
    "missing_df = pd.read_csv(\"missing.csv\")\n",
    "\n",
    "new_rows = missing_df[~missing_df['RIC'].isin(all_df['RIC'])]\n",
    "\n",
    "combined_df = pd.concat([all_df, new_rows], ignore_index=True)\n",
    "\n",
    "combined_df.to_csv(\"all_stocks_data.csv\", index=False)\n",
    "\n",
    "print(f\"Added {len(new_rows)} new rows to all_stocks_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_df = pd.read_csv(\"all_stocks_data.csv\")\n",
    "attempt2_df = pd.read_csv(\"attempt2.csv\")\n",
    "\n",
    "# Get the RICs present in attempt2.csv\n",
    "ric_to_replace = attempt2_df['RIC'].unique()\n",
    "\n",
    "# Keep only rows in all_df whose RIC is NOT in attempt2_df\n",
    "all_df_filtered = all_df[~all_df['RIC'].isin(ric_to_replace)]\n",
    "\n",
    "# Append the attempt2 data\n",
    "combined_df = pd.concat([all_df_filtered, attempt2_df], ignore_index=True)\n",
    "\n",
    "# Save back to all_stocks_data.csv\n",
    "combined_df.to_csv(\"all_stocks_data.csv\", index=False)\n",
    "\n",
    "print(f\"Replaced data for {len(ric_to_replace)} RICs with attempt2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b0c85a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RIC            0\n",
       "Date           0\n",
       "price     332682\n",
       "tri          376\n",
       "volume    332768\n",
       "cap         3050\n",
       "bid          499\n",
       "ask          570\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"all_stocks_data.csv\").isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
